{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling_and_normalization(sample,sampling_length=256*256,padding=10):\n",
    "    length = sample.size(1)\n",
    "    if length<sampling_length:\n",
    "        pad = int((sampling_length-length)/2)\n",
    "        sample = torch.cat((torch.zeros((1,pad)),sample,torch.zeros((1,pad))),-1)\n",
    "    sample = torch.cat((torch.zeros((1,padding)),sample,torch.zeros((1,padding))),-1)\n",
    "    length = sample.size(1)\n",
    "    random_num = np.random.randint(low=0, high=(length-sampling_length-1))\n",
    "    sample = sample[:,random_num:random_num+sampling_length]\n",
    "    \n",
    "    #normalization\n",
    "    #channel=（channel-mean）/std\n",
    "    mean = 2e-05\n",
    "    std = 0.05\n",
    "    sample = (sample-mean)/std\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_sampling_and_normalization(sample,sampling_length=256*256):\n",
    "    length = sample.size(1)\n",
    "    if length<sampling_length:\n",
    "        pad = int(sampling_length-length)\n",
    "        sample = torch.cat((sample,torch.zeros((1,pad))),-1)\n",
    "    sample = sample[:,:sampling_length]\n",
    "    #normalization\n",
    "    #channel=（channel-mean）/std\n",
    "    mean = 2e-05\n",
    "    std = 0.05\n",
    "    sample = (sample-mean)/std\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dataset(Dataset):\n",
    "    def __init__(self, df_path, train = False):\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.train = train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sample_1_name = self.df.iloc[idx]['sample 1']\n",
    "        sample_1_path = '/scratch/cz2064/myjupyter/Time_Series/Data/data_VoxCeleb/wav/'+sample_1_name\n",
    "        sample_1,_ = torchaudio.load(sample_1_path)\n",
    "        \n",
    "        sample_2_name = self.df.iloc[idx]['sample 2']\n",
    "        sample_2_path = '/scratch/cz2064/myjupyter/Time_Series/Data/data_VoxCeleb/wav/'+sample_2_name\n",
    "        sample_2,_ = torchaudio.load(sample_2_path)\n",
    "        \n",
    "        if self.train:\n",
    "            sample_1_tensor = random_sampling_and_normalization(sample_1)\n",
    "            sample_2_tensor = random_sampling_and_normalization(sample_2)\n",
    "        else:\n",
    "            sample_1_tensor = center_sampling_and_normalization(sample_1)\n",
    "            sample_2_tensor = center_sampling_and_normalization(sample_2)\n",
    "            \n",
    "            \n",
    "        label = self.df.loc[idx,'True or False']\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        sample = {'x1': sample_1_tensor, 'x2': sample_2_tensor, 'y': label}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_path = '/scratch/cz2064/myjupyter/Time_Series/notebook/train.csv'\n",
    "val_df_path = '/scratch/cz2064/myjupyter/Time_Series/notebook/val.csv'\n",
    "test_df_path = '/scratch/cz2064/myjupyter/Time_Series/notebook/test.csv'\n",
    "BATCH_SIZE = 32\n",
    "#train_loader = DataLoader(my_dataset(train_df_path,train = True), batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_sampler = torch.utils.data.sampler.RandomSampler(my_dataset(train_df_path,train = True)\\\n",
    "                                                       ,num_samples=50000,replacement=True)\n",
    "train_loader = DataLoader(my_dataset(train_df_path,train = True), batch_size=BATCH_SIZE, \\\n",
    "                          sampler = train_sampler,num_workers=16)\n",
    "val_loader = DataLoader(my_dataset(val_df_path), batch_size=BATCH_SIZE, shuffle=True,num_workers=16)\n",
    "test_loader = DataLoader(my_dataset(test_df_path), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ = iter(train_loader)\n",
    "sample_1 = next(iter_)['x1']\n",
    "sample_2 = next(iter_)['x2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 65536])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG_1D(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG_1D, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        #self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool1d(kernel_size=5, stride=5)]\n",
    "            else:\n",
    "                layers += [nn.Conv1d(in_channels, x, kernel_size=10, padding=5),\n",
    "                           nn.BatchNorm1d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool1d(21)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN = VGG_1D('VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNN(sample_1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.cnn = model_CNN\n",
    "        self.fc1 = nn.Linear(512*3,2048)\n",
    "        self.activation_fc1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(2048,1024)\n",
    "        self.activation_fc2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(1024,2)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.cnn(x1)\n",
    "        x2 = self.cnn(x2)\n",
    "        \n",
    "        x_add = x1+x2\n",
    "        x_minus = x1-x2\n",
    "        x_multiply = x1*x2\n",
    "        x = torch.cat((x_add, x_minus, x_multiply),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation_fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation_fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-44fe875190ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/cz2064/envs/dl4med/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-878b5038a3ef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cz2064/envs/dl4med/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ff702f1a337f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#out = self.classifier(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cz2064/envs/dl4med/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cz2064/envs/dl4med/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cz2064/envs/dl4med/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cz2064/envs/dl4med/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    258\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 259\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model(sample_1,sample_2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader=train_loader, val_loader=val_loader, learning_rate=1e-4, num_epoch=100):\n",
    "    start_time = time.time()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "    \n",
    "    train_loss_return = []\n",
    "    train_acc_return = []\n",
    "    val_loss_return = []\n",
    "    val_acc_return = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        # Training steps\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predictions = []\n",
    "        truths = []\n",
    "        model.train()\n",
    "        train_loss_list = []\n",
    "        for i, (sample) in enumerate(train_loader):\n",
    "            sample_1 = sample['x1'].to(device)\n",
    "            sample_2 = sample['x2'].to(device)\n",
    "            labels = sample['y'].to(device)\n",
    "            outputs = model(sample_1,sample_2)\n",
    "            pred = outputs.data.max(-1)[1]\n",
    "            predictions += list(pred.cpu().numpy())\n",
    "            truths += list(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum()\n",
    "            model.zero_grad()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            print(loss)\n",
    "            train_loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # report performance\n",
    "        acc = (100 * correct / total)\n",
    "        train_acc_return.append(acc)\n",
    "        train_loss_every_epoch = np.average(train_loss_list)\n",
    "        train_loss_return.append(train_loss_every_epoch)\n",
    "        print('----------Epoch{:2d}/{:2d}----------'.format(epoch+1,num_epoch))\n",
    "        print('Train set | Loss: {:6.4f} | Accuracy: {:4.2f}% '.format(train_loss_every_epoch, acc))\n",
    "        \n",
    "        # Evaluate after every epochh\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        truths = []\n",
    "        val_loss_list = []\n",
    "        with torch.no_grad():\n",
    "            for i, (sample) in enumerate(val_loader):\n",
    "                sample_1 = sample['x1'].to(device)\n",
    "                sample_2 = sample['x2'].to(device)\n",
    "                labels = sample['y'].to(device)\n",
    "                outputs = model(sample_1,sample_2)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss_list.append(loss.item())\n",
    "                pred = outputs.data.max(-1)[1]\n",
    "                predictions += list(pred.cpu().numpy())\n",
    "                truths += list(labels.cpu().numpy())\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum()\n",
    "            # report performance\n",
    "            acc = (100 * correct / total)\n",
    "            val_acc_return.append(acc)\n",
    "            val_loss_every_epoch = np.average(val_loss_list)\n",
    "            val_loss_return.append(val_loss_every_epoch)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model_wts = model.state_dict()\n",
    "            save_model(model,train_loss_return,train_acc_return,val_loss_return,val_acc_return,best_model_wts)\n",
    "            elapse = time.strftime('%H:%M:%S', time.gmtime(int((time.time() - start_time))))\n",
    "            print('Test set | Loss: {:6.4f} | Accuracy: {:4.2f}% | time elapse: {:>9}'\\\n",
    "                  .format(val_loss_every_epoch, acc,elapse))\n",
    "    return model,train_loss_return,train_acc_return,val_loss_return,val_acc_return,best_model_wts\n",
    "\n",
    "def save_model(model,train_loss_return,train_acc_return,val_loss_return,val_acc_return,best_model_wts):\n",
    "    state = {'best_model_wts':best_model_wts, 'model':model, \\\n",
    "             'train_loss':train_loss_return, 'train_acc':train_acc_return,\\\n",
    "             'val_loss':val_loss_return, 'val_acc':val_acc_return}\n",
    "    torch.save(state, 'checkpoint_CNN.pt')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/scratch/cz2064/myjupyter/Time_Series/notebook/python_files/Model_CNN_VGG16/checkpoint_CNN.pt'\n",
    "model.load_state_dict(torch.load(path)['best_model_wts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7178, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6687, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6843, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6907, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7469, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6059, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6141, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7399, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5939, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5328, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5981, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5910, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6679, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5127, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4667, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6105, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5172, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5521, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4146, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9d3046b5d0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-e770fa31cc8f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, learning_rate, num_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0msample_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0msample_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/scratch/cz2064/myjupyter/Time_Series/notebook/python_files/\\\n",
    "Model_CNN_VGG16/checkpoint_CNN.pt',map_location=torch.device(device))['best_model_wts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_path = '/scratch/cz2064/myjupyter/Time_Series/notebook/test.csv'\n",
    "test_loader = DataLoader(my_dataset(test_df_path), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):   \n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_score = []\n",
    "    y_pre = []\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (sample) in enumerate(dataloader):\n",
    "        sample_1 = sample['x1'].to(device)\n",
    "        sample_2 = sample['x2'].to(device)\n",
    "        label = sample['y'].to('cpu',dtype=torch.long)\n",
    "        y_true += label.tolist()\n",
    "\n",
    "        output = model(sample_1,sample_2)\n",
    "        output = F.softmax(output,dim=1)\n",
    "        output = output.to('cpu')\n",
    "        if y_score == []:\n",
    "            y_score = np.array(output.detach().numpy())\n",
    "        else:\n",
    "            y_score = np.concatenate((y_score,output.detach().numpy()),axis = 0)\n",
    "    for i in y_score:\n",
    "        y_pre.append(list(i).index(max(i)))\n",
    "    return y_true,y_pre,y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true,y_pre,y_score = evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_df_path)\n",
    "test_df['pre'] = y_pre\n",
    "test_df['score'] = np.expand_dims(np.array(y_score),2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True or False</th>\n",
       "      <th>sample 1</th>\n",
       "      <th>sample 2</th>\n",
       "      <th>pre</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>id10270/x6uYqmx31kE/00001.wav</td>\n",
       "      <td>id10270/8jEAjG6SegY/00008.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0.697631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>id10270/x6uYqmx31kE/00001.wav</td>\n",
       "      <td>id10300/ize_eiCFEg0/00003.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>id10270/x6uYqmx31kE/00001.wav</td>\n",
       "      <td>id10270/GWXujl-xAVM/00017.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>id10270/x6uYqmx31kE/00001.wav</td>\n",
       "      <td>id10273/0OCW1HUxZyg/00001.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>id10270/x6uYqmx31kE/00001.wav</td>\n",
       "      <td>id10270/8jEAjG6SegY/00022.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True or False                       sample 1  \\\n",
       "0              1  id10270/x6uYqmx31kE/00001.wav   \n",
       "1              0  id10270/x6uYqmx31kE/00001.wav   \n",
       "2              1  id10270/x6uYqmx31kE/00001.wav   \n",
       "3              0  id10270/x6uYqmx31kE/00001.wav   \n",
       "4              1  id10270/x6uYqmx31kE/00001.wav   \n",
       "\n",
       "                        sample 2  pre     score  \n",
       "0  id10270/8jEAjG6SegY/00008.wav    1  0.697631  \n",
       "1  id10300/ize_eiCFEg0/00003.wav    0  0.000293  \n",
       "2  id10270/GWXujl-xAVM/00017.wav    1  0.754381  \n",
       "3  id10273/0OCW1HUxZyg/00001.wav    0  0.008987  \n",
       "4  id10270/8jEAjG6SegY/00022.wav    1  0.943433  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('Pre_VGG_16.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_curve(y_test,y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_classes = y_test.shape[1]\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    lw = 2\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC_curve(np.expand_dims(np.array(y_true),1),np.expand_dims(np.array(y_score),2)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
